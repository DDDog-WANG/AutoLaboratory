{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8589b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import robosuite as suite\n",
    "from robosuite import load_controller_config\n",
    "from robosuite.wrappers.gym_wrapper import GymWrapper\n",
    "import numpy as np\n",
    "from stable_baselines3 import DDPG , SAC, PPO\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from sb3_contrib.common.wrappers import TimeFeatureWrapper\n",
    "import argparse, os, glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,TensorDataset,random_split,DataLoader,SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d349c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.device(cuda)\n",
      "torch.cuda.device_count():  1\n",
      "Tesla V100-SXM2-16GB\n",
      "torch.cuda.current_device() 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"torch.device(cuda)\")\n",
    "    print(\"torch.cuda.device_count(): \", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name())\n",
    "    print(\"torch.cuda.current_device()\", torch.cuda.current_device())\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"torch.device(cpu)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444921b",
   "metadata": {},
   "source": [
    "# Load Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa62456",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: robot0_joint_pos_cos, Value.shape: (15,)\n",
      "Key: robot0_joint_pos_sin, Value.shape: (15,)\n",
      "Key: robot0_joint_vel, Value.shape: (15,)\n",
      "Key: robot0_right_eef_pos, Value.shape: (3,)\n",
      "Key: robot0_right_eef_quat, Value.shape: (4,)\n",
      "Key: robot0_right_gripper_qpos, Value.shape: (2,)\n",
      "Key: robot0_right_gripper_qvel, Value.shape: (2,)\n",
      "Key: robot0_left_eef_pos, Value.shape: (3,)\n",
      "Key: robot0_left_eef_quat, Value.shape: (4,)\n",
      "Key: robot0_left_gripper_qpos, Value.shape: (2,)\n",
      "Key: robot0_left_gripper_qvel, Value.shape: (2,)\n",
      "Key: tube_initial_pos, Value.shape: (3,)\n",
      "Key: pipette_initial_pos, Value.shape: (3,)\n",
      "Key: pipette004_pos, Value.shape: (3,)\n",
      "Key: pipette004_quat, Value.shape: (4,)\n",
      "Key: tube008_pos, Value.shape: (3,)\n",
      "Key: tube008_quat, Value.shape: (4,)\n",
      "Key: gripper1_to_pipette004, Value.shape: (3,)\n",
      "Key: pipette004_to_tube008, Value.shape: (3,)\n",
      "Key: tube008_to_initial, Value.shape: (3,)\n",
      "Key: pipette004_to_initial, Value.shape: (3,)\n",
      "Key: robot0_proprio-state, Value.shape: (67,)\n",
      "Key: object-state, Value.shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "controller_config = load_controller_config(default_controller=\"JOINT_POSITION\")\n",
    "env = suite.make(\n",
    "    \"MaholoLaboratory\",\n",
    "    \"Maholo\",\n",
    "    controller_configs=controller_config,\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=False,\n",
    "    use_camera_obs=False,\n",
    "    control_freq=50,\n",
    "    render_camera=\"frontview\",\n",
    "    render_gpu_device_id=0,\n",
    "    horizon=2000,\n",
    "    initialization_noise=None,\n",
    ")\n",
    "for key,value in env.reset().items():\n",
    "    print(f\"Key: {key}, Value.shape: {value.shape}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2046ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeFeature GYM Wrapper obs.shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "env = GymWrapper(env)\n",
    "env = TimeFeatureWrapper(env)\n",
    "print(f\"TimeFeature GYM Wrapper obs.shape: {env.reset().shape}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6309f9c8",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19415bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_actions: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"SAC\"\n",
    "weightpath = \"./models/maholo_SAC_JOINT.pth\"\n",
    "learning_rate = 0.001\n",
    "total_timesteps = 2000*10\n",
    "policy_kwargs = {'net_arch' : [512, 512, 512, 512], \n",
    "                'n_critics' : 4,\n",
    "                }\n",
    "n_actions = env.robots[0].action_dim\n",
    "# n_actions = 14\n",
    "print(f\"n_actions: {n_actions}\", flush=True)\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.2)\n",
    "\n",
    "if model_name == \"DDPG\":\n",
    "    model = DDPG(policy=\"MlpPolicy\", env=env, policy_kwargs=policy_kwargs)\n",
    "elif model_name == \"SAC\":\n",
    "    model = SAC(policy=\"MlpPolicy\", env=env, policy_kwargs=policy_kwargs)\n",
    "elif model_name == \"PPO\":\n",
    "    model = PPO(policy=\"MlpPolicy\", env=env)\n",
    "\n",
    "model.policy.load_state_dict(torch.load(weightpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bf7a8fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (latent_pi): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (mu): Linear(in_features=512, out_features=14, bias=True)\n",
       "  (log_std): Linear(in_features=512, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_model = model.policy.actor.float()\n",
    "actor_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02d48883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContinuousCritic(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (qf0): Sequential(\n",
       "    (0): Linear(in_features=114, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (qf1): Sequential(\n",
       "    (0): Linear(in_features=114, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (qf2): Sequential(\n",
       "    (0): Linear(in_features=114, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (qf3): Sequential(\n",
       "    (0): Linear(in_features=114, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_model = model.policy.critic.float()\n",
    "critic_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f66185b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14])\n"
     ]
    }
   ],
   "source": [
    "# test actor model\n",
    "test_input = torch.ones(1, 100).to(device)\n",
    "test_output = actor_model(test_input)\n",
    "print(test_output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "908c5859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic 1 Output: 0.0009697331115603447\n",
      "Critic 2 Output: 0.03320334851741791\n",
      "Critic 3 Output: -0.0352470688521862\n",
      "Critic 4 Output: -0.06494784355163574\n"
     ]
    }
   ],
   "source": [
    "# test critic model\n",
    "state_input = torch.ones(1, 100).to(device)\n",
    "action_input = torch.ones(1, 14).to(device)\n",
    "\n",
    "test_output = critic_model(state_input, action_input)\n",
    "for i, value in enumerate(test_output):\n",
    "    print(f\"Critic {i + 1} Output:\", value.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e9477",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a826e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs shape: torch.Size([10, 3000, 100])\n",
      "action shape: torch.Size([10, 3000, 14])\n"
     ]
    }
   ],
   "source": [
    "class NPYFolder(Dataset):\n",
    "    def __init__(self, obs_dir, action_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 使用glob匹配文件模式并获取所有的obs和action_OSC文件\n",
    "        self.obs_files = sorted(glob.glob(os.path.join(obs_dir, \"obs_seq_OSC_*\")))\n",
    "        self.action_files = sorted(glob.glob(os.path.join(action_dir, \"action_seq_OSC_*\")))\n",
    "        \n",
    "        assert len(self.obs_files) == len(self.action_files), \"Number of obs and action_OSC files must be the same!\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.obs_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        obs = np.load(self.obs_files[idx])\n",
    "        action = np.load(self.action_files[idx])\n",
    "        \n",
    "        sample = {'obs': obs, 'action': action}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "obs_dir = \"./collectdata/obs\"\n",
    "action_dir = \"./collectdata/action_OSC\"\n",
    "dataset = NPYFolder(obs_dir, action_dir)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "sample_batch = next(iter(dataloader))\n",
    "obs_shape = sample_batch['obs'].shape\n",
    "action_shape = sample_batch['action'].shape\n",
    "print(f\"obs shape: {obs_shape}\")\n",
    "print(f\"action shape: {action_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5eda99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(actor_model.parameters(), lr=0.00001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "def train(actor_model, device, dataloader, loss_function, optimizer):\n",
    "    losses_train = []\n",
    "    optimizer.step()\n",
    "    actor_model.train()\n",
    "    for databatch in dataloader:\n",
    "        for n in range(databatch['obs'].shape[1]):\n",
    "            actor_model.zero_grad()\n",
    "            x = databatch['obs'][:,n,:].float().to(device)\n",
    "            y = databatch['action'][:,n,:].float().to(device)\n",
    "            output = actor_model.forward(x)\n",
    "            loss = loss_function(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses_train.append(loss.item())\n",
    "    return np.mean(losses_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b43f53a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Train Loss: 0.003\n",
      "EPOCH: 1, Train Loss: 0.003\n",
      "EPOCH: 2, Train Loss: 0.003\n",
      "EPOCH: 3, Train Loss: 0.003\n",
      "EPOCH: 4, Train Loss: 0.003\n",
      "EPOCH: 5, Train Loss: 0.003\n",
      "EPOCH: 6, Train Loss: 0.003\n",
      "EPOCH: 7, Train Loss: 0.003\n",
      "EPOCH: 8, Train Loss: 0.003\n",
      "EPOCH: 9, Train Loss: 0.003\n",
      "EPOCH: 10, Train Loss: 0.003\n",
      "EPOCH: 11, Train Loss: 0.003\n",
      "EPOCH: 12, Train Loss: 0.003\n",
      "EPOCH: 13, Train Loss: 0.003\n",
      "EPOCH: 14, Train Loss: 0.003\n",
      "EPOCH: 15, Train Loss: 0.003\n",
      "EPOCH: 16, Train Loss: 0.003\n",
      "EPOCH: 17, Train Loss: 0.003\n",
      "EPOCH: 18, Train Loss: 0.003\n",
      "EPOCH: 19, Train Loss: 0.003\n",
      "EPOCH: 20, Train Loss: 0.003\n",
      "EPOCH: 21, Train Loss: 0.003\n",
      "EPOCH: 22, Train Loss: 0.003\n",
      "EPOCH: 23, Train Loss: 0.003\n",
      "EPOCH: 24, Train Loss: 0.003\n",
      "EPOCH: 25, Train Loss: 0.003\n",
      "EPOCH: 26, Train Loss: 0.003\n",
      "EPOCH: 27, Train Loss: 0.003\n",
      "EPOCH: 28, Train Loss: 0.003\n",
      "EPOCH: 29, Train Loss: 0.003\n",
      "EPOCH: 30, Train Loss: 0.003\n",
      "EPOCH: 31, Train Loss: 0.003\n",
      "EPOCH: 32, Train Loss: 0.003\n",
      "EPOCH: 33, Train Loss: 0.003\n",
      "EPOCH: 34, Train Loss: 0.003\n",
      "EPOCH: 35, Train Loss: 0.003\n",
      "EPOCH: 36, Train Loss: 0.003\n",
      "EPOCH: 37, Train Loss: 0.003\n",
      "EPOCH: 38, Train Loss: 0.003\n",
      "EPOCH: 39, Train Loss: 0.003\n",
      "EPOCH: 40, Train Loss: 0.003\n",
      "EPOCH: 41, Train Loss: 0.003\n",
      "EPOCH: 42, Train Loss: 0.003\n",
      "EPOCH: 43, Train Loss: 0.003\n",
      "EPOCH: 44, Train Loss: 0.003\n",
      "EPOCH: 45, Train Loss: 0.003\n",
      "EPOCH: 46, Train Loss: 0.003\n",
      "EPOCH: 47, Train Loss: 0.003\n",
      "EPOCH: 48, Train Loss: 0.003\n",
      "EPOCH: 49, Train Loss: 0.003\n",
      "EPOCH: 50, Train Loss: 0.003\n",
      "EPOCH: 51, Train Loss: 0.003\n",
      "EPOCH: 52, Train Loss: 0.003\n",
      "EPOCH: 53, Train Loss: 0.003\n",
      "EPOCH: 54, Train Loss: 0.003\n",
      "EPOCH: 55, Train Loss: 0.003\n",
      "EPOCH: 56, Train Loss: 0.003\n",
      "EPOCH: 57, Train Loss: 0.003\n",
      "EPOCH: 58, Train Loss: 0.003\n",
      "EPOCH: 59, Train Loss: 0.003\n",
      "EPOCH: 60, Train Loss: 0.003\n",
      "EPOCH: 61, Train Loss: 0.003\n",
      "EPOCH: 62, Train Loss: 0.003\n",
      "EPOCH: 63, Train Loss: 0.003\n",
      "EPOCH: 64, Train Loss: 0.003\n",
      "EPOCH: 65, Train Loss: 0.003\n",
      "EPOCH: 66, Train Loss: 0.003\n",
      "EPOCH: 67, Train Loss: 0.003\n",
      "EPOCH: 68, Train Loss: 0.003\n",
      "EPOCH: 69, Train Loss: 0.003\n",
      "EPOCH: 70, Train Loss: 0.003\n",
      "EPOCH: 71, Train Loss: 0.003\n",
      "EPOCH: 72, Train Loss: 0.003\n",
      "EPOCH: 73, Train Loss: 0.003\n",
      "EPOCH: 74, Train Loss: 0.003\n",
      "EPOCH: 75, Train Loss: 0.003\n",
      "EPOCH: 76, Train Loss: 0.003\n",
      "EPOCH: 77, Train Loss: 0.003\n",
      "EPOCH: 78, Train Loss: 0.003\n",
      "EPOCH: 79, Train Loss: 0.003\n",
      "EPOCH: 80, Train Loss: 0.003\n",
      "EPOCH: 81, Train Loss: 0.003\n",
      "EPOCH: 82, Train Loss: 0.003\n",
      "EPOCH: 83, Train Loss: 0.003\n",
      "EPOCH: 84, Train Loss: 0.003\n",
      "EPOCH: 85, Train Loss: 0.003\n",
      "EPOCH: 86, Train Loss: 0.003\n",
      "EPOCH: 87, Train Loss: 0.003\n",
      "EPOCH: 88, Train Loss: 0.003\n",
      "EPOCH: 89, Train Loss: 0.003\n",
      "EPOCH: 90, Train Loss: 0.003\n",
      "EPOCH: 91, Train Loss: 0.003\n",
      "EPOCH: 92, Train Loss: 0.003\n",
      "EPOCH: 93, Train Loss: 0.003\n",
      "EPOCH: 94, Train Loss: 0.003\n",
      "EPOCH: 95, Train Loss: 0.003\n",
      "EPOCH: 96, Train Loss: 0.003\n",
      "EPOCH: 97, Train Loss: 0.003\n",
      "EPOCH: 98, Train Loss: 0.003\n",
      "EPOCH: 99, Train Loss: 0.003\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    loss_train = train(actor_model, device, dataloader, loss_function, optimizer)\n",
    "    scheduler.step()\n",
    "    print('EPOCH: {}, Train Loss: {:.3f}'.format(epoch, loss_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e60e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ./models/maholo_SAC_actor_weights.pth\n"
     ]
    }
   ],
   "source": [
    "weightpath = \"./models/maholo_SAC_OSC_Actor.pth\"\n",
    "torch.save(actor_model.state_dict(), weightpath)\n",
    "print(\"Saved to\", savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b26c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23026494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightpath = \"./models/maholo_SAC_OSC.pth\"\n",
    "policy_kwargs = {'net_arch' : [512, 512, 512, 512], \n",
    "                'n_critics' : 4,\n",
    "                }\n",
    "model = SAC(policy=\"MlpPolicy\", env=env, policy_kwargs=policy_kwargs)\n",
    "# model.policy.actor.load_state_dict(torch.load(weightpath))\n",
    "model.policy.load_state_dict(torch.load(weightpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81712a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073a694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63c938f0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7088d246",
   "metadata": {},
   "source": [
    "# Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a4e0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = suite.make(\n",
    "    env_name=\"Lift\",\n",
    "    robots=\"Panda\",\n",
    "    has_renderer=True,\n",
    "    has_offscreen_renderer=True,\n",
    "    use_camera_obs=False,\n",
    "    control_freq=50,\n",
    "    horizon = 50,\n",
    ")\n",
    "env = GymWrapper(env)\n",
    "env = TimeFeatureWrapper(env)\n",
    "model = DDPG.load(modelpath, env = env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff41f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "obs = env.reset()\n",
    "while not done:\n",
    "    action, _states = model.predict(obs, deterministic = True)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    env.unwrapped.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d01bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
